{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tensorflow\n",
        "from tqdm import tqdm\n",
        "from keras.models import Model\n",
        "from keras.layers import Input,Dense,Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.merge import add\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "metadata": {
        "id": "4W1pSOzDqlW0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_json_file(json_file_name):\n",
        "  file_obj=open(json_file_name)\n",
        "  all_data=json.load(file_obj)\n",
        "  unique_code_to_word_mapping=all_data['unique_code_to_word_mapping']\n",
        "  train_image_encoded_captions=all_data['train_image_encoded_captions']\n",
        "  file_obj.close()\n",
        "  return unique_code_to_word_mapping,train_image_encoded_captions"
      ],
      "metadata": {
        "id": "1BnaYefjzNox"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_file_name=\"/content/drive/MyDrive/Colab Notebooks/Image Captioning/json_files/all_data.json\"\n",
        "unique_code_to_word_mapping,train_image_encoded_captions=load_json_file(json_file_name)"
      ],
      "metadata": {
        "id": "qhGjW0rm0Gd6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pickle_file(pickle_file_name):\n",
        "  train_image_features=pickle.load(open(pickle_file_name,\"rb\"))\n",
        "  return train_image_features"
      ],
      "metadata": {
        "id": "_4ign3iLcTgM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_features_pickle=\"/content/drive/MyDrive/Colab Notebooks/Image Captioning/pickle_files/train_image_features.pkl\"\n",
        "train_image_features=load_pickle_file(train_image_features_pickle)"
      ],
      "metadata": {
        "id": "uO0d_Pi3cTno"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_generator(train_image_encoded_captions,train_image_features,batch_size,vocabulary_size,max_caption_length):\n",
        "  all_train_features=[]\n",
        "  all_sentences=[]\n",
        "  all_next_words=[]\n",
        "  temp_size=batch_size\n",
        "  for image_name in tqdm(train_image_encoded_captions):\n",
        "    temp_size-=1\n",
        "    for caption in train_image_encoded_captions[image_name]:\n",
        "      for index in range(1,max_caption_length):\n",
        "        sentence_now=caption[0:index]\n",
        "        next_word=caption[index]\n",
        "        sentence_now=pad_sequences([sentence_now], maxlen=max_caption_length, padding='post')[0]\n",
        "        categorical_word=to_categorical([next_word],vocabulary_size)[0]\n",
        "        all_train_features.append(train_image_features[image_name])\n",
        "        all_sentences.append(sentence_now)\n",
        "        all_next_words.append(categorical_word)\n",
        "    if(temp_size==0):\n",
        "      yield [[np.array(all_train_features), np.array(all_sentences)], np.array(all_next_words)]\n",
        "      all_train_features=[]\n",
        "      all_sentences=[]\n",
        "      all_next_words=[]\n",
        "      temp_size=batch_size"
      ],
      "metadata": {
        "id": "xM4OTLksYHhJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_lstm_model(vocabulary_size,max_caption_length):\n",
        "  input_layer1=Input(shape=(2048,))\n",
        "  dropout_1=Dropout(0.2)(input_layer1)\n",
        "  hidden_layer1=Dense(256,activation='relu')(dropout_1)\n",
        "  input_layer2=Input(shape=(max_caption_length,))\n",
        "  embedding_1=Embedding(vocabulary_size,256)(input_layer2)\n",
        "  dropout_2=Dropout(0.2)(embedding_1)\n",
        "  lstm_1=LSTM(256)(dropout_2)\n",
        "  add_1=add([hidden_layer1,lstm_1])\n",
        "  hidden_layer2=Dense(256,activation='relu')(add_1)\n",
        "  output_layer=Dense(vocabulary_size,activation='softmax')(hidden_layer2)\n",
        "  lstm_model=Model(inputs=[input_layer1,input_layer2],outputs=output_layer)\n",
        "  return lstm_model"
      ],
      "metadata": {
        "id": "Uz7CwkX38YG0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_caption_length=38\n",
        "vocabulary_size=len(unique_code_to_word_mapping)\n",
        "epochs=7\n",
        "batch_size=5\n",
        "steps=len(train_image_encoded_captions)//batch_size\n",
        "lstm_model=make_lstm_model(vocabulary_size,max_caption_length)\n",
        "lstm_model.summary()\n",
        "lstm_model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "for i in range(epochs):\n",
        "  generator=create_generator(train_image_encoded_captions,train_image_features,batch_size,vocabulary_size,max_caption_length)\n",
        "  lstm_model.fit_generator(generator,epochs=1,steps_per_epoch=steps,verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pag7lUXFdK1j",
        "outputId": "2f411ebe-cae0-4763-ddca-9a7547ea45e9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 38)]         0           []                               \n",
            "                                                                                                  \n",
            " input_1 (InputLayer)           [(None, 2048)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 38, 256)      1619712     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2048)         0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 38, 256)      0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 256)          524544      ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    (None, 256)          525312      ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 256)          0           ['dense[0][0]',                  \n",
            "                                                                  'lstm[0][0]']                   \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          65792       ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 6327)         1626039     ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,361,399\n",
            "Trainable params: 4,361,399\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "100%|██████████| 6000/6000 [05:10<00:00, 19.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 311s - loss: 1.6819 - accuracy: 0.7220 - 311s/epoch - 259ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 6000/6000 [05:00<00:00, 19.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 301s - loss: 1.2689 - accuracy: 0.7540 - 301s/epoch - 251ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 6000/6000 [04:59<00:00, 20.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 300s - loss: 1.1104 - accuracy: 0.7686 - 300s/epoch - 250ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 6000/6000 [05:01<00:00, 19.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 302s - loss: 1.0142 - accuracy: 0.7790 - 302s/epoch - 251ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 6000/6000 [05:03<00:00, 19.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 303s - loss: 0.9485 - accuracy: 0.7872 - 303s/epoch - 253ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 6000/6000 [04:59<00:00, 20.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 300s - loss: 0.8950 - accuracy: 0.7942 - 300s/epoch - 250ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 6000/6000 [04:57<00:00, 20.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1200/1200 - 297s - loss: 0.8554 - accuracy: 0.8002 - 297s/epoch - 248ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pickle_dump(lstm_model_pickle):\n",
        "  pickle.dump(lstm_model,open(lstm_model_pickle,\"wb\"))"
      ],
      "metadata": {
        "id": "wCyVHeU51sf-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model_pickle=\"/content/drive/MyDrive/Colab Notebooks/Image Captioning/pickle_files/lstm_model.pkl\"\n",
        "create_pickle_dump(lstm_model_pickle)"
      ],
      "metadata": {
        "id": "0rLsFzBu4X-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f8e9cc0-efde-402f-c7bc-ec672d73c489"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://e636b3bd-70c5-448b-847e-d878af36c4e1/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:<keras.layers.recurrent.LSTM object at 0x7fe238083f10> has the same name 'LSTM' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTM'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7fe238083050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-FBeDN734qtP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}