# Image-Captioning-Project

#For Model 1 (CNN+LSTM)
# Download the MSCOCO dataset from the below URL
# http://images.cocodataset.org/zips/train2014.zip
# Download Annotations File from the below URL
# http://images.cocodataset.org/annotations/annotations_trainval2014.zip
# Extract the zip files and place it in google drive

There are 5 files which should be executed cell by cell in following order
1) read_and_preprocess_data.ipynb
2) vocabulary_generator.ipynb
3) feature_extraction.ipynb
4) training_model.ipynb
5) testing_model.ipynb

#For Model 2(With Visual attention)
Code need to be executed in Google Colab with GPU selected as runtime

# Download the MSCOCO dataset from the below URL
# http://images.cocodataset.org/zips/train2014.zip
# Download Annotations File from the below URL
# http://images.cocodataset.org/annotations/annotations_trainval2014.zip
# Extract the zip files and place it in google drive
#Place the Model2_VisualAttention.ipynb in the google drive
#Execute all the cells of the file sequentially